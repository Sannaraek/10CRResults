{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file(filepath):\n",
    "\tdataframe = pd.read_csv(filepath, header=None, delim_whitespace=True)\n",
    "\treturn dataframe.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = load_file('dataset/UCI/train/X_train.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a single file as a numpy array\n",
    "def load_file(filepath):\n",
    "\tdataframe = pd.read_csv(filepath, header=None, delim_whitespace=True)\n",
    "\treturn dataframe.values\n",
    " \n",
    "# load a list of files, such as x, y, z data for a given variable\n",
    "def load_group(filenames, prefix=''):\n",
    "\tloaded = list()\n",
    "\tfor name in filenames:\n",
    "\t\tdata = load_file(prefix + name)\n",
    "\t\tloaded.append(data)\n",
    "\t# stack group so that features are the 3rd dimension\n",
    "\tloaded = np.dstack(loaded)\n",
    "\treturn loaded\n",
    " \n",
    "# load a dataset group, such as train or test\n",
    "def load_dataset(group, prefix=''):\n",
    "\tfilepath = prefix + group + '/inertia/'\n",
    "\tfilenames = list()\n",
    "\t# body acceleration\n",
    "\tfilenames += ['total_acc_x_'+group+'.txt', 'total_acc_y_'+group+'.txt', 'total_acc_z_'+group+'.txt']\n",
    "\t# body gyroscope\n",
    "\tfilenames += ['body_gyro_x_'+group+'.txt', 'body_gyro_y_'+group+'.txt', 'body_gyro_z_'+group+'.txt']\n",
    "\t# load input data\n",
    "\tX = load_group(filenames, filepath)\n",
    "\t# load class output\n",
    "\ty = load_file(prefix + group + '/y_'+group+'.txt')\n",
    "\treturn X, y\n",
    "\n",
    "def segmentData(accData,time_step,step):\n",
    "    segmentAccData = list()\n",
    "    for i in range(0, accData.shape[0] - time_step,step):\n",
    "        segmentAccData.append(accData[i:i+time_step,:])\n",
    "    return segmentAccData\n",
    "    \n",
    "# load all train\n",
    "trainX, trainy = load_dataset('train', 'dataset/UCI/')\n",
    "trainy = np.asarray([x - 1 for x in trainy])\n",
    "\n",
    "# print(trainX.shape, trainy.shape)\n",
    "# load all test\n",
    "testX, testy = load_dataset('test', 'dataset/UCI/')\n",
    "# soo it starts at 0\n",
    "testy = np.asarray([x - 1 for x in testy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = list()\n",
    "for x in range(0,trainX.shape[2]):\n",
    "    datasets.append(np.concatenate((trainX[:,:,x],testX[:,:,x]), axis = 0))\n",
    "datasets = np.dstack(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_normalize(dataset,mu,sigma):\n",
    "    return (dataset - mu)/sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "meanAcc = np.mean(datasets[:,:,:3])\n",
    "stdAcc = np.std(datasets[:,:,:3])\n",
    "varAcc = np.var(datasets[:,:,:3])\n",
    "stackedFeaturesAcc = np.hstack((meanAcc,stdAcc,varAcc))\n",
    "\n",
    "meanGyro = np.mean(datasets[:,:,3:])\n",
    "stdGyro = np.std(datasets[:,:,3:])\n",
    "varGyro = np.var(datasets[:,:,3:])\n",
    "stackedFeaturesGyro = np.hstack((meanGyro,stdGyro,varGyro))\n",
    "\n",
    "normalizedTrainAcc = (trainX[:,:,:3] - meanAcc) / stdAcc\n",
    "normalizedTrainGyro = (trainX[:,:,3:] - meanGyro) / stdGyro\n",
    "\n",
    "normalizedTestAcc = (testX[:,:,:3] - meanAcc) / stdAcc\n",
    "normalizedTestGyro = (testX[:,:,3:] - meanGyro) / stdGyro\n",
    "\n",
    "\n",
    "normalizedAllAcc = (datasets[:,:,:3] - meanAcc) / stdAcc\n",
    "normalizedAllGyro = (datasets[:,:,3:] - meanGyro) / stdGyro\n",
    "\n",
    "stackedFeatures = np.vstack((stackedFeaturesAcc,stackedFeaturesGyro))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizedX = np.dstack((normalizedTrainAcc,normalizedTrainGyro))\n",
    "normalizedEval = np.dstack((normalizedTestAcc,normalizedTestGyro))\n",
    "normalizedAll = np.dstack((normalizedAllAcc,normalizedAllGyro))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataName = 'UCI'\n",
    "os.makedirs('datasetStand/'+dataName+ '/train', exist_ok=True)\n",
    "np.savetxt('datasetStand/'+dataName+ '/train/AccX'+dataName+'.csv', normalizedX[:,:,0], delimiter=',')\n",
    "np.savetxt('datasetStand/'+dataName+ '/train/AccY'+dataName+'.csv', normalizedX[:,:,1], delimiter=',')\n",
    "np.savetxt('datasetStand/'+dataName+ '/train/AccZ'+dataName+'.csv', normalizedX[:,:,2], delimiter=',')\n",
    "np.savetxt('datasetStand/'+dataName+ '/train/GyroX'+dataName+'.csv', normalizedX[:,:,3], delimiter=',')\n",
    "np.savetxt('datasetStand/'+dataName+ '/train/GyroY'+dataName+'.csv', normalizedX[:,:,4], delimiter=',')\n",
    "np.savetxt('datasetStand/'+dataName+ '/train/GyroZ'+dataName+'.csv', normalizedX[:,:,5], delimiter=',')\n",
    "np.savetxt('datasetStand/'+dataName+ '/train/Label'+dataName+'.csv', trainy, delimiter=',')\n",
    "\n",
    "os.makedirs('datasetStand/'+dataName+ '/eval', exist_ok=True)\n",
    "np.savetxt('datasetStand/'+dataName+ '/eval/AccX'+dataName+'.csv', normalizedEval[:,:,0], delimiter=',')\n",
    "np.savetxt('datasetStand/'+dataName+ '/eval/AccY'+dataName+'.csv', normalizedEval[:,:,1], delimiter=',')\n",
    "np.savetxt('datasetStand/'+dataName+ '/eval/AccZ'+dataName+'.csv', normalizedEval[:,:,2], delimiter=',')\n",
    "np.savetxt('datasetStand/'+dataName+ '/eval/GyroX'+dataName+'.csv', normalizedEval[:,:,3], delimiter=',')\n",
    "np.savetxt('datasetStand/'+dataName+ '/eval/GyroY'+dataName+'.csv', normalizedEval[:,:,4], delimiter=',')\n",
    "np.savetxt('datasetStand/'+dataName+ '/eval/GyroZ'+dataName+'.csv', normalizedEval[:,:,5], delimiter=',')\n",
    "np.savetxt('datasetStand/'+dataName+ '/eval/Label'+dataName+'.csv', testy, delimiter=',')\n",
    "\n",
    "os.makedirs('datasetStand/'+dataName+ '/all', exist_ok=True)\n",
    "np.savetxt('datasetStand/'+dataName+ '/all/AccX'+dataName+'.csv', normalizedAll[:,:,0], delimiter=',')\n",
    "np.savetxt('datasetStand/'+dataName+ '/all/AccY'+dataName+'.csv', normalizedAll[:,:,1], delimiter=',')\n",
    "np.savetxt('datasetStand/'+dataName+ '/all/AccZ'+dataName+'.csv', normalizedAll[:,:,2], delimiter=',')\n",
    "np.savetxt('datasetStand/'+dataName+ '/all/GyroX'+dataName+'.csv', normalizedAll[:,:,3], delimiter=',')\n",
    "np.savetxt('datasetStand/'+dataName+ '/all/GyroY'+dataName+'.csv', normalizedAll[:,:,4], delimiter=',')\n",
    "np.savetxt('datasetStand/'+dataName+ '/all/GyroZ'+dataName+'.csv', normalizedAll[:,:,5], delimiter=',')\n",
    "np.savetxt('datasetStand/'+dataName+ '/all/Label'+dataName+'.csv', testy, delimiter=',')\n",
    "\n",
    "os.makedirs('datasetStand/'+dataName+ '/features', exist_ok=True)\n",
    "np.savetxt('datasetStand/'+dataName+ '/features/mean-std-var'+dataName+'.csv', stackedFeatures, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
